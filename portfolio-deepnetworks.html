<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Paul Vangerow - Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: DevFolio
  * Updated: Jul 27 2023 with Bootstrap v5.3.1
  * Template URL: https://bootstrapmade.com/devfolio-bootstrap-portfolio-html-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center justify-content-between">

      <h1 class="logo"><a href="index.html">Paul Vangerow</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link scrollto" href="#portfolio">Projects</a></li>
          <li><a class="nav-link scrollto " href="#resume">Experience</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <div class="hero hero-single route bg-image" style="background-image: url(assets/img/ProjectImages/DL/background.png)">
    <div class="overlay-mf"></div>
    <div class="hero-content display-table">
      <div class="table-cell">
        <div class="container">
          <h2 class="hero-title mb-4">Generative Models</h2>
          <ol class="breadcrumb d-flex justify-content-center">
            <li class="breadcrumb-item">
              <a href="index.html">Home</a>
            </li>
            <li class="breadcrumb-item active">Generative Models</li>
          </ol>
        </div>
      </div>
    </div>
  </div>

  <main id="main">

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row gy-4">
          <div class="col-lg-5">
            <div class="portfolio-details-slider swiper">
              <div class="swiper-wrapper align-items-center">

                <div class="swiper-slide">
                  <div class="portfolio-img">
                    <img src="assets/img/ProjectImages/DL/GAN_Images.png" alt="">
                  </div>
                </div>

                <div class="swiper-slide">
                  <div class="portfolio-img">
                    <img src="assets/img/ProjectImages/DL/GAN_Training.png" alt="">
                  </div>
                </div>

                <div class="swiper-slide">
                  <div class="portfolio-img">
                    <img src="assets/img/ProjectImages/DL/VAE_Embeddings.png" alt="">
                  </div>
                </div>

                <div class="swiper-slide">
                  <div class="portfolio-img">
                    <img src="assets/img/ProjectImages/DL/VAE_Images.png" alt="">
                  </div>
                </div>

              </div>
              <div class="swiper-pagination"></div>
            </div>
          </div>

          <div class="col-lg-7">
            <div class="row">
              <div class="col-lg-7">
                <div class="portfolio-description">
                  <h2>Description</h3>
                  <p>
                    Coursework for the Deep Learning Module. It involved building, training and tuning two types of 
                    latent space generative models. The first was a Convolutional VAE trained on MNIST and
                    the second a DCGAN trained on CIFAR-10.
                  </p>
                </div>
              </div>

              <div class="col-lg-5">
                <div class="portfolio-info">
                  <h3>Details</h3>
                  <table>
                    <tr>
                      <td class="title">Skills:</td>
                      <td>
                        <span class="tag">Deep Learning</span>
                        <span class="tag">VAE</span>
                        <span class="tag">GAN</span>
                        <span class="tag">Pytorch</span>
                        <span class="tag">Python</span>
                      </td>
                    </tr>
                    <tr>
                      <td class="title">Scope:</td>
                      <td>University</td>
                    </tr>
                    <tr>
                      <td class="title">Date:</td>
                      <td>February 2024</td>
                    </tr>
                  </table>
                </div>
              </div>
            </div>
            
            <div class="portfolio-description">
              <h2>Components</h2>
              <ul>
                <li>
                  <strong>Variational Auto Encoder</strong>: The VAE had to be built from scratch, requiring extensive
                  research and testing to ensure a sufficient performance was achieved. Most of the design decisions
                  made were a result of repeated experimentation and testing:
                  <ul>
                    <li><strong>Cost Function</strong>: A reconstruction loss added to a KLD term for the distribution divergence from 
                      the prior, modified by a parameter beta. For the reconstruction loss there were two main options: the 
                      commonly used MSE, but also BCE with a Sigmoid activation (as MNIST uses only one channel). Extensive explorations
                      were conducted using both options and very little difference was observed besides requiring different magnitudes 
                      of Beta. In the end, the MSE loss was settled on since it produced a more disentangled latent space for each 
                      image class (which could be seen in the TSNE embeddings).
                      
                      The KLD term was implemented using the analytical form with a Normal Gaussian Prior. This prior was chosen
                      for two main reasons: Image generation and Latent Space Exploration. Using a Gaussian Normal helped with 
                      image generation as it ensured that the latent space representations of all the features were similar, 
                      meaning generation could involve simply filling the latent space with random samples from a Normal Gaussian 
                      which could then be passed through the decoder to generate images. The second is that the normal gaussian 
                      has a logvar and mean of zero, resulting in a number of network activations being driven to 0, promoting 
                      sparsity and disentangelement of the latent space.
                    </li>
                    <li><strong>Structure</strong>: Additional explorations were made in regards to the architecture of the
                      encoder and decoder. To reduce the number of parameters two downconvolution layers were used with stride 2,
                      reducing the image size from 28x28 to 7x7, followed by two linear layers to bottleneck the forwards pass and
                      encourage a good latent space representation; these layers were interspersed with batchnorms and leaky ReLU
                      layers to increase convergence speed. The decoder was implemented as a reversed encoder.
                    </li>
                  </ul>
                </li>
                <li>
                  <strong>Deep Convolutional Generative Adverserial Network</strong>: The GAN was built based on the model proposed by 
                  <a href="https://arxiv.org/abs/1511.06434" style="color: #d9c4df;"> Unsupervised Representation Learning with Deep Convolutional Generative 
                    Adversarial Networks</a> and tuned once again through testing different modifications:
                  <ul>
                    <li><strong>Kernel Size</strong>: Performance was tested with different Kernel Sizes, 3x3 had very poor performance, 
                      producing images with strange colours and patterns. Kernels of 7x7, 9x9 and 11x11 generated images that appear 
                      similar to those created by the 5x5, though with seemingly fewer details or discernable shapes (possibly because many 
                      kernels act on each pixel causing some level of 'smoothing').
                    </li>
                    <li><strong>Latent Space</strong>: Different latent space sizes were also explored, a size of 200 resulted in more 
                      diverse images, though with fewer discernable items; a size of 50 created less diverse and lower quality images,
                      though with more distinction. Running the model with 75 seemed to capture the best of both worlds, producing images  
                      containing a larger array of diverse yet recognisable items.
                    </li>
                    <li><strong>Epochs</strong> When testing it was discovered that models with loss curves that remain at an 
                      'equilibrium' of sort for a number of epochs tended to perform better when simply trained for longer. As 
                      the network is adverserial, the loss is no real indication of overall performance as the Generator and 
                      Discriminator can improve at the same rate. The network was trained for 20, 50 and 100 epochs, demonstrating 
                      overall improved image generation after longer training. Analysing loss curves showed that going for too long 
                      resulted in overfitting as the Discriminator slowly learned all the images in the dataset, naturally making it 
                      discriminate more efficiently.
                    </li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
          <div>&nbsp;</div>

        </div>

      </div>
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <div class="copyright-box">
            <p class="copyright">&copy; Copyright <strong>DevFolio</strong>. All Rights Reserved</p>
            <div class="credits">
              <!--
              All the links in the footer should remain intact.
              You can delete the links only if you purchased the pro version.
              Licensing information: https://bootstrapmade.com/license/
              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=DevFolio
            -->
              Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>